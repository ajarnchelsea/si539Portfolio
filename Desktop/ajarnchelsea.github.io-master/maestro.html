<!DOCTYPE html>
<html>
<head>
	<meta charset = "UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Chelsea Miller | UX Design</title>
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.0/css/bootstrap.min.css">
	<link rel="stylesheet" type="text/css" href="css/contact.css"/>
	<link rel="stylesheet" type="text/css" href="css/normalize.css" />
	<link rel="stylesheet" type="text/css" href="css/style.css"/>
	<script src="https://use.fontawesome.com/0acf032063.js"></script>
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-90963537-1', 'auto');
	  ga('send', 'pageview');
	</script>
</head>


<body>
	<!-- ======= Navigation start ======= -->
	<div class="navigation-exterior">
		<div class="navigation-interior">
			<div class="navigation-link">
				<span id="title"><a href="index.html">CHELSEA MILLER</a></span>
			</div>
			<ul>
			<div class="navigation-links">
				<li><a href="index.html" class="navigation-link" style="text-decoration-line: underline;">Projects</a></li>
				<li><a href="about.html" class="navigation-link">About</a></li>
				<li><a href="resume.html" class="navigation-link">Resume</a></li>
			</div>
			</ul>
		</div>
	</div>
	<!-- ======= Navigation end ======= -->
	
	<!-- ======= Interior start ======= -->
	<div>

		<!-- ======= Project start ======= -->
		<div class="portfoliobody">
			<div class="summary">
				<h1>MAESTRO</h1>
				<h2>Developing conducting students’ confidence on the podium, one gesture at a time.</h2>
				<img src="images/maestro/maestro_kinect.png" alt="" style="margin-top:45px;">
				<p>
					<b>Timeline:</b> January – December 2017<br/><br/>
					<b>Methods:</b>  Heuristic Evaluation, Interaction Mapping, Interviews, Personas, Usability Testing, Survey Design & Analysis, Digital Prototyping<br/><br/>
					<b>My Role:</b> UX Researcher and Engineer<br/><br/>
					I was one of two UX researchers/engineers on a team with 5 software engineers and a musical conducting consultant. Our work on Maestro was facilitated by U-M’s Multidisciplinary Design Program, housed in the College of Engineering. I designed and led the research study, and jointly designed and implemented the user interface with my partner.
				</p>
			</div>
		
			<div class="gray">
				<h2>Overview</h2>
				<video class="vid" controls id="papervid" loop="" name="schema explorer" src="images/maestro/brown.mp4" width="55%" height="auto"></video>
				<p class="caption"><em>Dr. Andrea Brown conducting the Maestro system on display at the Campus of the Future Symposium on October 27th, 2017.</em></p>
				<p><b>Maestro</b> is a computer vision software tool that allows beginning conducting students to practice without a live ensemble.<br/><br/>

				At the beginner level, conducting students face <b>two main challenges</b>: gaining control of <b>gestural technique</b>, and <b>developing confidence</b> on the podium. Due to the difficulty of finding musicians and ensembles to conduct live outside of the classroom, many students currently practice by conducting along to pre recorded music or reviewing their technique either in the mirror or through video recordings. <b>These methods are passive</b>, in that students follow the music. Conductors, however, influence the shape, style, and direction of sounds in real time. <b>Conducting students are learning how to lead music - not follow it - and there is currently a lack of tools to facilitate this learning process.</b><br/><br/>

				There are several essential parts of a single conducting gesture: <b>the preparation, action point, sustain, and release</b>. The size and speed of the gesture communicate the character of the sound from the conductor to the ensemble. <b>Maestro allows users to practice and gain control of these fundamental movements.</b><br/><br/>
				</p>
			</div>

			<div class="white">
				<h2>Phase I: Discovery</h2>
				<p>Our team was sponsored by Dr. Andrea Brown, Assistant Director of Bands at the University of Michigan, who developed the Maestro concept and recruited a team of students to develop the the first version of the system’s algorithm and UI in 2016. The 2016 system algorithm focused on a gesture’s preparation speed and action point, and provided users with audio feedback in the form of a static audio clip. <br/><br/>

				In Maestro’s second year, our team started out by evaluating the 2016 system; improving the quality of algorithmic analysis; and creating a better user experience in terms of system navigability and gestural discoverability.<br/><br/>

				The 2016 team did not have a dedicated UX researcher or designer, so my partner and I first <b>created a research plan</b> to both <b>discover insights about the 2016 system’s usability</b> as well as to <b>learn more about our target users</b>. We wanted to build a front-end experience that not only improved upon the 2016 framework, but also had a solid foundation supported by thorough user research.
				</p>
				<h3>System Map</h3>
				<p>I created a system map to better understand the how the front-end interfaces with the algorithm and sound synthesis engine, as well as to identify features to evaluate in our first round of usability testing.</p>
				<img src="images/maestro/freeplay.png" alt="">
				<h3>Interviews and Usability Tests</h3>
				<p>To maximize our time with our participants, we developed a test plan consisting of a 30-minute semi-structured interview about participants’ <b>conducting experiences, practice habits, and attitudes towards technology in music education</b>, followed by a 30 minute usability evaluation. Using insights gathered from our interaction map, we created usability tasks that asked users to navigate through the system and conduct gestures in both Freeplay and Lesson modes. We also created a post-test questionnaire that asked participants to rate system features and various aspects of the experience on a 5-point Likert scale.</p>
				<img src="images/maestro/moderating.png" alt="">
				<p class="caption" style="margin-top:-30px;"><em>Here I am, moderating a usability test in the Earl V. Moore music building.</em></p>
				<p>We <b>recruited 5 music students</b>, 2 of whom were <b>enrolled in the university’s beginning conducting course</b>, and 3 of whom <b>had completed the course</b>. Sessions were conducted in practice rooms in the Earl V. Moore music building on campus, to better replicate the context in which Maestro would be used in the future.<br/><br/> 

				I moderated 3 usability tests, and acted as notetaker for 2 tests while my partner moderated. We video recorded the tests for future review and analysis, and asked participants to follow a talk-aloud protocol so that we could understand their attitudes and opinions while using various system features.</p>
				<h3>Key Insights</h3>
				<p>After analyzing our findings from our video recordings and surveys by making a virtual affinity wall, we identified several key insights that shaped our prototyping and implementation phases:</p>
				<ol>
					<li><b>Users responded positively to the Kinect skeleton.</b> Users valued the visual feedback in the form on the Kinect skeleton because they could focus on their posture and technique without the additional distraction present in the video screen; they mentioned they weren’t looking at the video feedback unless they wanted to monitor a very subtle gesture.</li>
					<li><b>Users struggled with the information architecture of Lesson mode.</b> Lessons were organized under "Levels 1-4", with a sub-structure of "Lessons 1-10."" There is very little semantic information encoded in these names, and users weren’t sure how these Levels or Lessons were related. Users had a difficult time remembering whether they had completed Lesson 1 in Level 1 or in Level 2, since the lesson itself had the same name.</li>
					<li><b>First-time users didn’t know how to begin interacting with the system in Freeplay mode.</b> They weren't sure whether they could start conducting right away, and after realizing that they could not, were not sure which button they needed to press to start the process.</li>
				</ol>
				<h3>Personas</h3>
				<p>Before we began prototyping, we distilled our findings from our interviews and usability tests to create personas of three target users. We used these personas to represent our users and help us justify our design decisions to our team and to the faculty panels we presented to each quarter.</p>
				<div id="personaphotos">
					<img src="images/maestro/maestropersona1.png" alt=""/>
					<img src="images/maestro/maestropersona2.png" alt=""/>
					<img src="images/maestro/maestropersona3.png" alt="" />

				</div>
			</div>

			<div class="gray">
				<h2>Phase II: Prototyping</h2>
				<p>My partner and I split up the design process by features: <b>I designed the onboarding process, the system navigation, the architecture of the lesson modes, and the post-lesson feedback visualizations</b>, while my partner designed the Freeplay and Lesson modes. Dr. Brown was invaluable in providing us with guidance on organizing lessons by concepts as well as on how we could translate our findings from our interviews towards creating a useful feedback and reflection process after users complete each lesson.<br/><br/> 

				We used Sketch and InVision to rapidly iterate on our high fidelity design after discussing design decisions with our team and mentors each week.<br/><br/></p>
				<video class="vid" controls muted id="papervid" loop="" name="schema explorer" src="images/maestro/protovid.mp4" width="55%" height="auto"></video>
			</div>

			<div class="white">
				<h2>Phase III: Implementation</h2>
				<p>Starting Fall 2017, our team transitioned from design to development. We used XAML to build the new system, and modified the associated C# code when necessary. The developers on our team had made updates to the algorithm to expand its analysis to sustain duration and release types, and improved the overall accuracy and consistency of recognizing each state of the conducting gesture. The sound synthesis subteam implemented their sound synth engine, which featured 4 synthesized instruments: clarinet, oboe, horn, and bassoon. <br/><br/>


				The screen capture below shows a user selecting instrument(s) for audio feedback. Users can select one instrument, or create an ensemble by selecting multiple instruments.</p>
				<video class="vid" controls id="papervid" loop="" name="schema explorer" src="images/maestro/freeplay.mp4" width="55%" height="auto"></video>


				<p>In addition to creating a more consistent visual style, we implemented several key features during development:</p>
				<ul>
					<li><b>Calibrate and Reset Body buttons moved to reflect order in which users should click them.</b> Users must calibrate the system before using it, so we moved it from the bottom corner of the interface to the top. Additionally, users had been confused about why the Reset Body button was placed next to the Calibrate button - they weren’t sure what the difference was. We moved it below Calibrate to visually separate their functions and the order in which users will use them.</li>
					<li><b>Tooltips added to guide users through Calibration, Reset Body, and system status features.</b> We used toolips to provide users with additional information on the Calibrate and Reset Body buttons, as well as on the color encodings on the Kinect skeleton as they pertain to System Status.</li>
					<li><b>Video feedback minimized. We moved the video feedback screen to the corner of the interface, as users expressed that they were using it only to make minor adjustments or observe nuances in their form.</b> This gave us room to implement the audio feedback selection on the sidebar.</li>
					<li><b>Lesson mode restructured and renamed.</b> Lesson levels are grouped in a sequence similar to that used in conducting courses: single sounds, sustains, dynamics, and patterns.</li>
				</ul>
				<p>The screen capture below shows a user navigating through the system's onboarding process and Lesson mode.</p>
				<video class="vid" controls muted id="papervid" name="schema explorer" src="images/maestro/onboarding.mp4" width="55%" height="auto"></video>
			</div>

			<div class="gray">
				<h2>Phase IV: Validation</h2>
				<p>To validate the user experience of our final design, we conducted another round of usability tests with <b>8 conducting students from the School of Music, Theatre, and Dance</b>. Two usability tasks were conducted. The first task evaluated the <b>discoverability of gestural interactions</b> within the “Freeplay” mode by instructing participants to discover and express gestures of different dynamic levels, dynamic changes, and release types. The second task evaluated the <b>ease of navigability through the Lesson mode interface</b> by asking participants to navigate to, select, and describe their understanding of the Lesson screen. The evaluation resulted in a  task completion rate of 100% for all 4 tasks across all eight participants.

				After completion of both tasks, we distributed surveys to collect feedback on participants’ perception of their experience with the system using a 5-pt. Likert scale (1 - strongly disagree, 3 - neutral, and 5 - strongly agree) with the bottom 20% of scores dropped. Tasks with mean scores of 4+ passed validation, and are highlighted in bold below:</p>
				<h4 style="margin-bottom:40px;">Discoverability/Responsiveness</h4>
				<ul>
					<li>Overall, the system responded appropriately to my gestures: 3.75</li>
					<li>Overall, I understood when I performed a gesture accurately: 4</li>
					<li>Overall, I understood when I did NOT perform a gesture accurately: 3.75</li>
					<li>The system responded to my action points accurately: 4</li>
					<li>The system responded with the appropriate dynamics related to my gesture: 3.25</li>
					<li>The system responded to my releases accurately: 3</li>
				</ul>

				<h4 style="margin-bottom:40px;">Lesson Navigability</h4>
				<ul>
					<li>I was able to determine which lesson was appropriate to start with: 5</li>
					<li>I understood the purpose of each lesson: 4.75</li>
					<li>I was able to navigate through lessons without confusion: 4.5</li>
					<li>I was able to clearly see the lesson instructions from the conducting position: 4</li>
				</ul>
			</div>

			<div class="white">
				<h2>Phase V: Recommendations</h2>
				<p>During the Fall 2017 round of validation testing, we identified both successful improvements to the system as well as areas for continued work and future growth. Key findings are outlined below, and are followed by recommendations for the 2018 Maestro team.</p>
				<ul>
					<li><b>Need for improved help & documentation for first time users.</b> Create a Tutorial Mode that has the same functions as Freeplay mode, but steps the user through each feature step by step. For example, a popup would tell the user to first calibrate; then, there might be a popup pointing their attention to the system status feedback methods (described below) with an encouragement to conduct a gesture; there could be a popup telling users that they can press Reset Body any time, but particularly when their skeleton disappears; and finally, there could be a popup encouraging users to change the instrument selected for feedback, and that they can create “ensembles” by selecting multiple instruments.</li>
					<li><b>Streamline the calibration and setup process.</b>Moving forward, the ideal solution would be to seamlessly build calibration into the user’s first gesture. However, several intermediary improvements could be made. The team should create a more proactive instruction for users to calibrate. One possible solution would be to create a popup that appears when users enter Freeplay mode and doesn’t go away until user has calibrated. The Calibration instruction screen could automatically disappear once calibration has been successfully completed, so users don’t have to walk back to the laptop to hit the “Done” button. Additionally, there should be a visual or audio indication that calibration has been completed successfully.</li>
					<li><b>Clarify color encodings used to represent system status.</b>Users do seem to understand the color encoding that green means “ready”, but didn’t as clearly understand the encoding of the blue circle. One participant said that it might be helpful to distinguish between the “playing music” status and the “not ready” status by using different colors. Additionally, the onboarding/tutorial process could help ensure that users are aware of this color encoding on the Kinect skeleton.</li>
				</ul>
				
			</div>

		</div>
		<!-- ======= Project end ======= -->
				
		<!-- ======= Footer start ======= -->
		<div class="footer" id="footer">
			<ul id="footlist">
				<li><a href="https://www.linkedin.com/in/millerchelsealauren" target="_blank"><i class="fa fa-linkedin-square fa-2x" aria-hidden="true"></i></a></li>
				<li><a href="https://www.instagram.com/millerchelsea/" target="_blank"><i class="fa fa-instagram fa-2x" aria-hidden="true"></i></a></li>
				<li><a href="http://www.github.com/ajarnchelsea" target="_blank"><i class="fa fa-github-square fa-2x" aria-hidden="true"></i></a></li>
				<li><a href="mailto:milchels@gmail.com" target="_top"><i class="fa fa-envelope-square fa-2x" aria-hidden="true"></i></a></li>
			</ul>				
			<p>Coded by hand, with patience and love. © Chelsea Miller 2017</p>
		</div>
		<!-- ======= Footer end ======= -->

	</div>
	<!-- ======= Interior end ======= -->
</body>
</html>